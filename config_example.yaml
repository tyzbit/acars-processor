# yaml-language-server: $schema=./schema.json

# Purpose: Forward all human-created messages to New Relic and Discord
# Environment variables are substituted at runtime by acars-processor
ACARSProcessorSettings:
  Database:
    Enabled: true
    SQLiteDatabasePath: ./messages.db
    Type: sqlite
  ACARSHub:
    MaxConcurrentRequests: 1
    ACARS:
      Host: &acarshubhost acarshub
      Port: 15550
      SelectedFields: &selectedfields
        - ACARSProcessor.ACARSDramaTailNumberLink
        - ACARSProcessor.FlightNumber
        - ACARSProcessor.FrequencyMhz
        - ACARSProcessor.From
        - ACARSProcessor.ImageLink
        - ACARSProcessor.MessageText
        - ACARSProcessor.PhotosLink
        - ACARSProcessor.SignalLeveldBm
        - ACARSProcessor.TailCode
        - ACARSProcessor.ThumbnailLink
        - ACARSProcessor.TrackingLink
        - ACARSProcessor.TranslateLink
        - ACARSProcessor.UnixTimestamp

    VDLM2:
      Host: *acarshubhost
      Port: 15555
      SelectedFields: *selectedfields

Steps:
  - Filter: { Builtin: { HasText: true } }
  - Filter: { Builtin: { DictionaryPhraseLengthMinimum: 2 } }
  - Filter:
      Builtin:
        PreviousMessageSimilarity:
          Similarity: 0.9
          MaximumLookBehind: 10000
          DontFilterIfLonger: false
  - Annotate:
      Tar1090:
        URL: http://tar1090
        ReferenceGeolocation: ${reference_geolocation}
  - Filter:
      Builtin:
        FilterOnFailure: true
        BelowDistanceMi: 100.0
  - Filter:
      Ollama:
        Model: &ollamamodel qwen3:30b-a3b
        URL: &ollamaurl http://ollama:11434
        FilterOnFailure: true
        MaxRetryAttempts: 1
        MaxRetryDelaySeconds: 5
        Timeout: 30
        Options: &ollamaopts [
            { Name: num_predict, Value: 150 }, # Maximum number of tokens (words, kinda) to generate
            { Name: temperature, Value: 0.4 }, # Creativity (0.0-2.0)
            { Name: top_p, Value: 0.2 }, # Answer diversity with top_k (0.0-1.0)
            { Name: top_k, Value: 20 }, # Answer diversity (ex 0-100)
            { Name: frequency_penalty, Value: 1.1 }, # Penalize repeated tokens (0-2.0)
            { Name: num_gpu, Value: 40 }, # Number of layers to offload to GPU
          ]
        UserPrompt: |
          You are reviewing messages from both humans and programatically
          generated messages to decide if they should be forwarded on because
          they were written by a person.

          DO NOT forward if the message matches any of these rules:
          - Is uniformly structured like a table, or comma separated.
          - Contains multiple segments with /M, /N, /P, /Q, /R, /S, /T, /V
            and numbers, without any human prose.
          - Starts with or is dominated by system headers/codes: FLR/, FDR/, 
            FPN/, POSRPT, POSN, CFDS, ACMS, AIDS, ATSU, MDC REPORT, ACARS AUTO,
            ENGINE TREND, ECAM 1/2, ECAM only lines, LRU, P/N.
          - Pure telemetry: comma/slash-separated numbers/codes, or blocks like
            /M /N /P /Q /R /S with no prose.
          - No clause with a verb and fewer than 4 alphabetic words separated by
            spaces. 

          DO forward if the message matches any of these rules:
          - Contains natural-language sentences or human prose.
            Human prose may contain technical terms or acronyms but will always
            include a human-meaningful question or statement.
          - Greetings/sign-offs, for example: HI, HELLO, BONJOUR,
            GOOD MORNING/EVENING, THANKS, THX, BRGRDS, CHEERS
          - A clear sentence/clause like WILL/IS/ARE/HAVE/NEED/CAN/PLEASE/
            QUESTION MARK followed by a verb, for example: PLEASE SEND WX.
          - Has /Q/ which is shorthand for asking a question in this context.
          - Operational prose about passengers,crew,med,medical,booking,
            rebooking/ramp-gate with at least some text that communicates a
            narrative.

          Based on these rules, should this message be forwarded?
  - Annotate:
      Ollama:
        Model: qwen3:30b-a3b
        URL: http://ollama-service:11434
        MaxRetryAttempts: 1
        MaxRetryDelaySeconds: 5
        Timeout: 30
        Options: [
            { Name: num_predict, Value: 150 }, # Maximum number of tokens (words, kinda) to generate
            { Name: temperature, Value: 0.4 }, # Creativity (0.0-2.0)
            { Name: top_p, Value: 0.2 }, # Answer diversity with top_k (0.0-1.0)
            { Name: top_k, Value: 20 }, # Answer diversity (ex 0-100)
            { Name: frequency_penalty, Value: 1.1 }, # Penalize repeated tokens (0-2.0)
            { Name: num_gpu, Value: 40 }, # Number of layers to offload to GPU
          ]
        UserPrompt:
          Rate this message on a scale of 1-100 for how angry it reads. Is the
          result greater than 50?
        SelectedFields:
          - ACARSProcessor.LLMProcessedNumber
          - ACARSProcessor.LLMQuestionAnswer
          - ACARSProcessor.LLMFeedbackText
          - ACARSProcessor.LLMProcessedText
  - Annotate:
      SelectedFields:
        - ACARSProcessor.ImageLink
        - ACARSProcessor.MessageText
        - ACARSProcessor.PhotosLink
        - ACARSProcessor.TailCode
        - ACARSProcessor.ThumbnailLink
        - ACARSProcessor.TrackingLink
        - ACARSProcessor.UnixTimestamp
        - ACARSProcessor.LLMProcessedNumber
        - ACARSProcessor.LLMQuestionAnswer
        - ACARSProcessor.LLMFeedbackText
  - Send:
      Discord:
        Embed: true
        EmbedColorFacetFields: [ACARSProcessor.From]
        URL: "${acars_discord_webhook}"
        FormatText: true
        FormatTimestamps: true
